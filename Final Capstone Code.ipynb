{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# CAPSTONE PROECT"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "THIS NOTEBOOK WILL BE MAINLY USED FOR THE CAPSTONE PROJECT FROM IBM DATA SCIENCE PROFESSIONAL CERTIFICATE"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 1. Import important libraries"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#!pip install --upgrade requests branca six jinja2 numpy chardet idna urllib3 certifi MarkupSafe\n!conda install -c conda-forge folium --yes\n#!conda install -c conda-forge geopy --yes\n!conda install -c conda-forge wordcloud==1.4.1 --yes\nimport numpy as np\nimport pandas as pd\nimport requests\nimport random\nfrom sklearn.cluster import KMeans\nfrom pandas.io.json import json_normalize\nimport folium\nfrom folium.plugins import MiniMap\nfrom geopy.geocoders import Nominatim\nimport json\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nfrom sklearn import metrics\nfrom PIL import Image\nimport matplotlib.patches as mpatches\nfrom wordcloud import WordCloud, get_single_color_func\nprint('Libraries imported.')",
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Solving environment: / ",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2. Load Neighborhoods in New York and Toronto from:"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "New York: https://ibm.box.com/shared/static/fbpwbovar7lf8p5sgddm06cgipa2rxpe.json\nToronto: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -q -O 'newyork_data.json' https://ibm.box.com/shared/static/fbpwbovar7lf8p5sgddm06cgipa2rxpe.json\nprint('Data downloaded!')\nprint('Loading data...')\nwith open('newyork_data.json') as json_data:\n    newyork_data = json.load(json_data)\n    \nprint('\\n...data loaded succesfully!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "##### 2.1.1. Let's take a look at the relevant data in a pandas dataframe"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "neighborhoods_ny = pd.DataFrame(columns = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'])\nfor data in newyork_data['features']:\n    borough = neighborhood_name = data['properties']['borough'] \n    neighborhood_name = data['properties']['name']\n        \n    neighborhood_latlon = data['geometry']['coordinates']\n    neighborhood_lat = neighborhood_latlon[1]\n    neighborhood_lon = neighborhood_latlon[0]\n    \n    neighborhoods_ny = neighborhoods_ny.append({'Borough': borough,\n                                          'Neighborhood': neighborhood_name,\n                                          'Latitude': neighborhood_lat,\n                                          'Longitude': neighborhood_lon}, ignore_index=True)\n\n#Take only neighborhoods from manhattan!\nneighborhoods_ny = neighborhoods_ny[neighborhoods_ny['Borough'] == 'Manhattan'].reset_index(drop=True)\nneighborhoods_ny.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(\"{} neighborhoods found in New York city.\".format(neighborhoods_ny.shape[0]))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "##### 2.2. Download and load Toronto data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "webPage = requests.get(\"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\")\nprint('Data downloaded!')\nprint('Loading data...')\nhtml = webPage.text                                                                       \ntableInit = html.find('<table class=\"wikitable sortable\">')                            \ntableFinal = html.find('</table>')                                                      \nhtmlTable = html[tableInit:tableFinal]\nprint('\\n...data loaded succesfully!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "###### 2.2.1. Let's take a look at the relevant data in a pandas dataframe"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "table = pd.read_html(htmlTable, header = 0)[0]                                            \ntable[\"Borough\"] = table[\"Borough\"].replace({\"Not assigned\":np.nan})                \ntable.dropna(inplace = True)                                                          \ntable.where(table != \"Not assigned\", table[\"Borough\"], axis = 0, inplace = True)      \njoinedRows = table.groupby(\"Postcode\")[\"Neighbourhood\"].apply(lambda x: \", \".join(x)) \ntable.drop_duplicates([\"Postcode\"],inplace = True)                                    \ndf = table.join(joinedRows, on = \"Postcode\", lsuffix='_single')                       \ndf.drop(columns = [\"Neighbourhood_single\"], inplace = True)                         \ndf.reset_index(drop = True, inplace = True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Add latitude and longitude from: http://cocl.us/Geospatial_data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -q -O 'Geospatial_Coordinates.csv' http://cocl.us/Geospatial_data\ngeo = pd.read_csv(\"Geospatial_Coordinates.csv\", index_col = 0)         \nneighborhoods_to = df.join(geo, on = \"Postcode\")\n\n#Take only those neighborhoods that contain the word Toronto\nneighborhoods_to = neighborhoods_to[neighborhoods_to['Borough'].str.contains('Toronto')].reset_index(drop=True)\nneighborhoods_to.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(\"\\n{} neighborhoods found in the city of Toronto.\".format(neighborhoods_to.shape[0]))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2.3. Visualize the neighborhoods in New York and Toronto"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "###### 2.3.1. Get center coordinates to visualize both cities at the same time"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "address = 'Manhattan, NY'\n\ngeolocator = Nominatim(user_agent=\"my-application\")\nlocation = geolocator.geocode(address)\nny_latitude = location.latitude\nny_longitude = location.longitude\nprint('The geograpical coordinate of New York City (Manhattan) are {}, {}.'.format(ny_latitude, ny_longitude))\n\naddress = 'Toronto'\n\nlocation = geolocator.geocode(address)\nto_latitude = location.latitude\nto_longitude = location.longitude\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(to_latitude, to_longitude))\n\ncenterLatitude = (ny_latitude + to_latitude)/2\ncenterLongitude = (ny_longitude + to_longitude)/2\n\nprint('\\nThe geograpical central coordinates are {}, {}.'.format(centerLatitude, centerLongitude))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "###### 2.3.2 Append New York and Toronto tables"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tmp = neighborhoods_to.drop(\"Postcode\",axis = 1)\ntmp.rename(columns = {\"Neighbourhood\":\"Neighborhood\"}, inplace = True)\ndf = neighborhoods_ny.append(tmp, True).reset_index(drop = True)\npd.set_option('max_rows', 6)\ndf",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_tony = folium.Map(location=[centerLatitude, centerLongitude], zoom_start=7, width='100%', height='100%')\n\nfor lat, lng, borough, neighborhood in zip(df['Latitude'], df['Longitude'], df['Borough'], df['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7).add_to(map_tony)\nmap_tony",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_tony = folium.Map(location=[ny_latitude, ny_longitude], zoom_start=11, width='100%', height='100%')\n\nfor lat, lng, borough, neighborhood in zip(df['Latitude'], df['Longitude'], df['Borough'], df['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7).add_to(map_tony)\n\nminimap = MiniMap(position = 'topleft', center_fixed = (ny_latitude, ny_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_tony)\n\nminimap = MiniMap(position='bottomright',  center_fixed = (to_latitude, to_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_tony)\nmap_tony",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_tony = folium.Map(location=[to_latitude, to_longitude], zoom_start=11, width='100%', height='100%')\n\nfor lat, lng, borough, neighborhood in zip(df['Latitude'], df['Longitude'], df['Borough'], df['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7).add_to(map_tony)\n\nminimap = MiniMap(position = 'topleft', center_fixed = (ny_latitude, ny_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_tony)\n\nminimap = MiniMap(position='bottomright',  center_fixed = (to_latitude, to_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_tony)\nmap_tony",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 3. Import data from Foursquare"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3.1. Setting up the credentials"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "CLIENT_ID = '2I0S3UDT4JPCUVSECPX2NUVA1DCGMOJCICB5PMJJIVQNMXHV' # your Foursquare ID\nCLIENT_SECRET = 'HR1NF5MW52YXVDV0KWI5G3XFVWXFRHRNOBYRQEUCGKXA10CL' # your Foursquare Secret\nVERSION = '20180604'\nLIMIT = 100\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3.2. Create and send the GET request"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "class color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n\ndef getNearbyVenues(names, boroughs, latitudes, longitudes, radius=500):\n    ind = 1\n    venues_list=[]\n    for name, borough, lat, lng in zip(names, boroughs, latitudes, longitudes):\n        tmp=[]\n        print(color.BOLD+str(ind)+\" | \"+name+color.END)\n        ind += 1\n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        #tmp.append([(j['venue']['name']) for j in results])\n        #for item in tmp[0]:\n        #    print(\"\\t\",item)\n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name,\n            borough,\n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood',\n                  'Borough',\n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    print(\"\\nDone!\")\n    return(nearby_venues)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tony_venues = getNearbyVenues(names=df['Neighborhood'],\n                                   boroughs = df['Borough'],\n                                   latitudes=df['Latitude'],\n                                   longitudes=df['Longitude']\n                                  )",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# one hot encoding\ntony_onehot = pd.get_dummies(tony_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntony_onehot['Neighborhood'] = tony_venues['Neighborhood'] \ntony_onehot['Borough'] = tony_venues['Borough']\ntony_onehot['Neighborhood Latitude'] = tony_venues['Neighborhood Latitude']\ntony_onehot['Neighborhood Longitude'] = tony_venues['Neighborhood Longitude']\n\n\n# move neighborhood column to the first column\nfixed_columns = [tony_onehot.columns[-1]] + list(tony_onehot.columns[:-1])\ntony_onehot = tony_onehot[fixed_columns]\n\ntony_grouped = tony_onehot.groupby(['Neighborhood','Borough','Neighborhood Latitude','Neighborhood Longitude']).mean().reset_index()\n\n#print(tony_venues.drop_duplicates([\"Neighborhood\"],inplace = False)['Neighborhood'].reset_index(drop=True))    \ntony_grouped",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 4.Clustering"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 4.1. Find centroids with K-means"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Finding best k\nplt.style.use(\"seaborn\")\nKs = 11\nmse = np.zeros((Ks-1))\ntony_grouped_clustering = tony_grouped.drop(['Neighborhood','Borough','Neighborhood Latitude','Neighborhood Longitude'], 1)\nfor n in range(1,Ks):\n    \n    # set number of clusters\n    kclusters = n\n    # run k-means clustering\n    kmeans = KMeans(n_clusters=kclusters, random_state=0, init = 'random', n_init = 15).fit(tony_grouped_clustering)\n    mse[n-1] = kmeans.inertia_\n\nplt.plot(range(1,Ks),mse)\nplt.xlabel(\"Number of clusters\")\nplt.ylabel(\"MSE\")\nplt.title(\"K selection\")\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "According to the elbow method, 5 clusters are enough for finding similarities!"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n# set number of clusters\nkclusters = 5\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0, init = 'random', n_init = 15).fit(tony_grouped_clustering)\n    \ntony_merged = df\n\n# add clustering labels\ntony_merged['Cluster Labels'] = kmeans.labels_\n\ntony_merged",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 4.2. Display clusters in maps"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# create map\nmap_clusters = folium.Map(location=[centerLatitude, centerLongitude], zoom_start=7, width='100%', height='100%')\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(tony_merged['Latitude'], tony_merged['Longitude'], tony_merged['Neighborhood'], tony_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# create map\nmap_clusters = folium.Map(location=[ny_latitude, ny_longitude], zoom_start=11, width='100%', height='100%')\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(tony_merged['Latitude'], tony_merged['Longitude'], tony_merged['Neighborhood'], tony_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \n\n\nminimap = MiniMap(position = 'topleft', center_fixed = (ny_latitude, ny_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_clusters)\n\nminimap = MiniMap(position='bottomright',  center_fixed = (to_latitude, to_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_clusters)\nmap_clusters",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# create map\nmap_clusters = folium.Map(location=[to_latitude, to_longitude], zoom_start=11, width='100%', height='100%')\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(tony_merged['Latitude'], tony_merged['Longitude'], tony_merged['Neighborhood'], tony_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \n\n\nminimap = MiniMap(position = 'topleft', center_fixed = (ny_latitude, ny_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_clusters)\n\nminimap = MiniMap(position='bottomright',  center_fixed = (to_latitude, to_longitude), zoom_level_fixed = 8)\nminimap.add_to(map_clusters)\nmap_clusters",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4.3.Analyse Centroids"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "cl1 = tony_merged.loc[tony_merged['Cluster Labels'] == 0, tony_merged.columns[[1] + list(range(5, tony_merged.shape[1]))]]\ncl1",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "cl1 = tony_merged.loc[tony_merged['Cluster Labels'] == 0, tony_merged.columns[[1] + list(range(5, tony_merged.shape[1]))]]\ncl1",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd.set_option('max_rows', 100)\ncl3 = tony_merged.loc[tony_merged['Cluster Labels'] == 2, tony_merged.columns[[1] + list(range(5, tony_merged.shape[1]))]]\ncl3",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "cl4 = tony_merged.loc[tony_merged['Cluster Labels'] == 3, tony_merged.columns[[1] + list(range(5, tony_merged.shape[1]))]]\ncl4",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "cl5 = tony_merged.loc[tony_merged['Cluster Labels'] == 4, tony_merged.columns[[1] + list(range(5, tony_merged.shape[1]))]]\ncl5",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 5.Data Visualization"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "##### 5.1. Waffle Chart"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def create_waffle_chart(categories, values, height, width, colormap, value_sign=''):\n\n    # compute the proportion of each category with respect to the total\n    total_values = sum(values)\n    category_proportions = [(float(value) / total_values) for value in values]\n\n    # compute the total number of tiles\n    total_num_tiles = width * height # total number of tiles\n    print ('Total number of tiles is', total_num_tiles)\n    \n    # compute the number of tiles for each catagory\n    tiles_per_category = [round(proportion * total_num_tiles) for proportion in category_proportions]\n\n    # print out number of tiles per category\n    for i, tiles in enumerate(tiles_per_category):\n        print (categories[i] + ': ' + str(tiles))\n    \n    # initialize the waffle chart as an empty matrix\n    waffle_chart = np.zeros((height, width))\n\n    # define indices to loop through waffle chart\n    category_index = 0\n    tile_index = 0\n\n    # populate the waffle chart\n    for col in range(width):\n        for row in range(height):\n            tile_index += 1\n\n            # if the number of tiles populated for the current category \n            # is equal to its corresponding allocated tiles...\n            if tile_index > sum(tiles_per_category[0:category_index]):\n                # ...proceed to the next category\n                category_index += 1    \n              # set the class value to an integer, which increases with class\n            waffle_chart[row, col] = category_index\n    \n    # instantiate a new figure object\n    fig = plt.figure()\n\n    # use matshow to display the waffle chart\n    plt.matshow(waffle_chart, cmap=colormap)\n    plt.colorbar()\n\n    # get the axis\n    ax = plt.gca()\n\n    # set minor ticks\n    ax.set_xticks(np.arange(-.5, (width), 1), minor=True)\n    ax.set_yticks(np.arange(-.5, (height), 1), minor=True)\n    \n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    \n    # add dridlines based on minor ticks\n    ax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n\n    plt.xticks([])\n    plt.yticks([])\n\n    # compute cumulative sum of individual categories to match color schemes between chart and legend\n    values_cumsum = np.cumsum(values)\n    total_values = values_cumsum[len(values_cumsum) - 1]\n    #print(values_cumsum)\n      # set the class value to an integer, which increases with class\n            waffle_chart[row, col] = category_index\n    \n    # instantiate a new figure object\n    fig = plt.figure()\n\n    # use matshow to display the waffle chart\n    plt.matshow(waffle_chart, cmap=colormap)\n    plt.colorbar()\n\n    # get the axis\n    ax = plt.gca()\n\n    # set minor ticks\n    ax.set_xticks(np.arange(-.5, (width), 1), minor=True)\n    ax.set_yticks(np.arange(-.5, (height), 1), minor=True)\n    \n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    \n    # add dridlines based on minor ticks\n    ax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n\n    plt.xticks([])\n    plt.yticks([])\n\n    # compute cumulative sum of individual categories to match color schemes between chart and legend\n    values_cumsum = np.cumsum(values)\n    total_values = values_cumsum[len(values_cumsum) - 1]\n    #print(values_cumsum)\n\n    ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "index = ['Cluster I', 'Cluster II', 'Cluster III', 'Cluster IV','Cluster V']\nportions = [cl5.shape[0], cl1.shape[0], cl4.shape[0], cl2.shape[0], cl3.shape[0]]\nwidth = 40 # width of chart\nheight = 10 # height of chart\n\ncategories = index # categories\nvalues = portions # correponding values of categories\n\ncolormap = plt.cm.coolwarm# color map class\ncreate_waffle_chart(categories, values, height, width, colormap)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 5.2 Word Cloud"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "word_string = \"\"\nfor neighborhood in tony_merged[\"Neighborhood\"]:\n    elements = \"\"\n    for element in neighborhood.split(\",\"):\n        elements += element.strip().replace(\" \", \"\") + \" \"\n    word_string += elements+\" \"\nword_string = word_string.replace(\".\",\"\")\n\ntmp = cl1[\"Neighborhood\"].tolist()\ncl1_list = []\nfor element in tmp:\n    cl1_list.extend(element.split(\", \"))\ncl1_list = [element.replace(\" \",\"\") for element in cl1_list]\n\ntmp = cl2[\"Neighborhood\"].tolist()\ncl2_list = []\nfor element in tmp:\n    cl2_list.extend(element.split(\", \"))\ncl2_list = [element.replace(\" \",\"\") for element in cl2_list]\n    \ntmp = cl3[\"Neighborhood\"].tolist()\ncl3_list = []\nfor element in tmp:\n    cl3_list.extend(element.split(\", \"))\ncl3_list = [element.replace(\" \",\"\") for element in cl3_list]\ncl3_list = [element.replace(\".\",\"\") for element in cl3_list]\n\ntmp = cl4[\"Neighborhood\"].tolist()\ncl4_list = []\nfor element in tmp:\n    cl4_list.extend(element.split(\", \"))\ncl4_list = [element.replace(\" \",\"\") for element in cl4_list]    \ntmp = cl5[\"Neighborhood\"].tolist()\ncl5_list = []\nfor element in tmp:\n    cl5_list.extend(element.split(\", \"))\ncl5_list = [element.replace(\" \",\"\") for element in cl5_list]\n\ncl1_list",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\ntmp = np.zeros((kmeans.cluster_centers_.shape))\ntmp[0,:] = kmeans.cluster_centers_[4,:]\ntmp[1,:] = kmeans.cluster_centers_[0,:]\ntmp[2,:] = kmeans.cluster_centers_[3,:]\ntmp[3,:] = kmeans.cluster_centers_[1,:]\ntmp[4,:] = kmeans.cluster_centers_[2,:]\nmaxi = []\nfor i in range(5):\n    maxi.extend(tmp[i,:].argsort()[-3:][::-1])\n    \nargs = np.asarray(list(set(maxi)))\ntable = pd.DataFrame(data = tmp[:,args.astype(int)], index = ['Cluster I', 'Cluster II', 'Cluster III', 'Cluster IV','Cluster V'], columns = tony_grouped_clustering.columns[args.astype(int)])\ntable = table.transpose()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "class GroupedColorFunc(object):\n    \"\"\"Create a color function object which assigns DIFFERENT SHADES of\n       specified colors to certain words based on the color to words mapping.\n\n       Uses wordcloud.get_single_color_func\n\n       Parameters\n       ----------\n       color_to_words : dict(str -> list(str))\n         A dictionary that maps a color to the list of words.\n\n       default_color : str\n         Color that will be assigned to a word that's not a member\n         of any value from color_to_words.\n    \"\"\"\n\n    def __init__(self, color_to_words, default_color):\n        self.color_func_to_words = [\n            (get_single_color_func(color), set(words))\n            for (color, words) in color_to_words.items()]\n\n        self.default_color_func = get_single_color_func(default_color)\n\n    def get_color_func(self, word):\n        \"\"\"Returns a single_color_func associated with the word\"\"\"\n        try:\n            color_func = next(\n                color_func for (color_func, words) in self.color_func_to_words\n                if word in words)\n        except StopIteration:\n            color_func = self.default_color_func\n\n        return color_func\n\n    def __call__(self, word, **kwargs):\n        return self.get_color_func(word)(word, **kwargs)\nwordcloud = WordCloud(width=1000, height=600, background_color='white', max_words = 500).generate(word_string)\n\ncolor_to_words = {\n    # words below will be colored with a green single color function\n    '#FF0000': cl1_list,\n    # will be colored with a red single color function\n    'black': cl2_list,\n    'blue': cl3_list,\n    '#00ff00': cl4_list,\n    'yellow': cl5_list\n}\n\ndefault_color = 'grey'\n\nprint('Word cloud created!')\n\nfig = plt.figure()\nfig.set_figwidth(500)\nfig.set_figheight(10)\n\ngrouped_color_func = GroupedColorFunc(color_to_words, default_color)\n\n# Apply our color function\nwordcloud.recolor(color_func=grouped_color_func)\n\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()    ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 5.3. Bar chart for clusters insights"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tmp = np.zeros((kmeans.cluster_centers_.shape))\ntmp[0,:] = kmeans.cluster_centers_[4,:]\ntmp[1,:] = kmeans.cluster_centers_[0,:]\ntmp[2,:] = kmeans.cluster_centers_[3,:]\ntmp[3,:] = kmeans.cluster_centers_[1,:]\ntmp[4,:] = kmeans.cluster_centers_[2,:]\nmaxi = []\nfor i in range(5):\n    maxi.extend(tmp[i,:].argsort()[-3:][::-1])\n    \nargs = np.asarray(list(set(maxi)))\ntable = pd.DataFrame(data = tmp[:,args.astype(int)], index = ['Cluster I', 'Cluster II', 'Cluster III', 'Cluster IV','Cluster V'], columns = tony_grouped_clustering.columns[args.astype(int)])\ntable = table.transpose()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.style.use('seaborn')\nax = table.plot(kind='bar', figsize=(15,6), rot=90, fontsize = 14, colormap = 'Paired')\nbars = ax.get_children()\nplt.title(\"Frequency of Ocurrence Within Each Cluster\")\nplt.ylabel(\"Frequency\")\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "maxi = []\nfor i in range(5):\n    maxi.extend(tmp[i,:].argsort()[-3:][::-1])\n    \nargs = np.asarray(list(set(maxi)))\ntable = pd.DataFrame(data = tmp[:,args.astype(int)], index = ['Cluster I', 'Cluster II', 'Cluster III', 'Cluster IV','Cluster V'], columns = tony_grouped_clustering.columns[args.astype(int)])\ntable = table.T\ntable.drop([\"Garden\"], inplace= True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nplt.style.use('seaborn')\nax = table.plot(kind='bar', figsize=(15,6), rot=90, fontsize = 14, colormap = \"Paired\")\nbars = ax.get_children()\nplt.title(\"Frequency of Ocurrence Within Each Cluster Without Garden!\")\nplt.ylabel(\"Frequency\")\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}